{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab314f6218d145b5885f91fa942f1e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50e20b7357fa48b3969587e3e87e2c1d",
              "IPY_MODEL_82cce4aef49a4b9aa8d7ccd6e7dd9fe7",
              "IPY_MODEL_3d363e7ccdb746d39c74158b52018c5e"
            ],
            "layout": "IPY_MODEL_694069893e9c4731b3d00f151915f076"
          }
        },
        "50e20b7357fa48b3969587e3e87e2c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f10a57170294b5695c9683e459466a0",
            "placeholder": "​",
            "style": "IPY_MODEL_8862c759eb794563bb87294e1d9fd978",
            "value": "adapter_model.bin: 100%"
          }
        },
        "82cce4aef49a4b9aa8d7ccd6e7dd9fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0c70b28e0794e058554016202b9c8bb",
            "max": 134264202,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b62b3ec32f441bcabe4a0e51eed8223",
            "value": 134264202
          }
        },
        "3d363e7ccdb746d39c74158b52018c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cc198f1931f4f2193329dc4e170f41f",
            "placeholder": "​",
            "style": "IPY_MODEL_01bacbea29d649a59badbc11fd8e669d",
            "value": " 134M/134M [00:17&lt;00:00, 11.9MB/s]"
          }
        },
        "694069893e9c4731b3d00f151915f076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f10a57170294b5695c9683e459466a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8862c759eb794563bb87294e1d9fd978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0c70b28e0794e058554016202b9c8bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b62b3ec32f441bcabe4a0e51eed8223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3cc198f1931f4f2193329dc4e170f41f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01bacbea29d649a59badbc11fd8e669d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bb971d46c5f43baaa369e8cf9f42a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b171419c1004259b237ee51d2388396",
              "IPY_MODEL_795430ae4931467da219d86a02c91c6c",
              "IPY_MODEL_94aee70b443a44bb8f097442fc4a67af"
            ],
            "layout": "IPY_MODEL_a813be4bf7454cd3969c39ce8f5d920b"
          }
        },
        "6b171419c1004259b237ee51d2388396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feda9e5c0751447485b0b562d28da2b8",
            "placeholder": "​",
            "style": "IPY_MODEL_f2d73faaecf3400bb98df686886465f8",
            "value": "Map: 100%"
          }
        },
        "795430ae4931467da219d86a02c91c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02be99b85b234526a6d5a5d60deee14c",
            "max": 1723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2ff98b438a94bd59c9209e03066f445",
            "value": 1723
          }
        },
        "94aee70b443a44bb8f097442fc4a67af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07391df100304ec89da591ffa2a34bed",
            "placeholder": "​",
            "style": "IPY_MODEL_618a882522664c6888b7c0a6aaba1152",
            "value": " 1723/1723 [00:00&lt;00:00, 7893.96 examples/s]"
          }
        },
        "a813be4bf7454cd3969c39ce8f5d920b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feda9e5c0751447485b0b562d28da2b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2d73faaecf3400bb98df686886465f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02be99b85b234526a6d5a5d60deee14c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ff98b438a94bd59c9209e03066f445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07391df100304ec89da591ffa2a34bed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618a882522664c6888b7c0a6aaba1152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06233f7b8b4348c39b657f0511e80198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d82e1110f414a8eaea7fc3758020e0c",
              "IPY_MODEL_0345d9676b024589916a74b4405d1115",
              "IPY_MODEL_5c30b816ba6b4affbc6bbca7fa2b8a18"
            ],
            "layout": "IPY_MODEL_e054372ce3e944089558741895912cf4"
          }
        },
        "5d82e1110f414a8eaea7fc3758020e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_201e44bd846f4b65a8ff37c7cf2a5c9d",
            "placeholder": "​",
            "style": "IPY_MODEL_57fa33d63de64a15808f73a7c8655bb9",
            "value": "Map: 100%"
          }
        },
        "0345d9676b024589916a74b4405d1115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eca1287f3c664545b067d543d8dffc8d",
            "max": 595,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5043f7ed4124dc19a27f50e2dbba2ed",
            "value": 595
          }
        },
        "5c30b816ba6b4affbc6bbca7fa2b8a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82599d1dcf3b4661bc8862cce4f26455",
            "placeholder": "​",
            "style": "IPY_MODEL_9e08f2e934d2451fba6cdd510e9d24a4",
            "value": " 595/595 [00:00&lt;00:00, 8427.56 examples/s]"
          }
        },
        "e054372ce3e944089558741895912cf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "201e44bd846f4b65a8ff37c7cf2a5c9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57fa33d63de64a15808f73a7c8655bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eca1287f3c664545b067d543d8dffc8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5043f7ed4124dc19a27f50e2dbba2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82599d1dcf3b4661bc8862cce4f26455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e08f2e934d2451fba6cdd510e9d24a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVa0caPZlogN"
      },
      "source": [
        "# Fine-Tuning LLMs with Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT5BjFcflZAh"
      },
      "source": [
        "## Step 1: Installing and importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLXwJqbjtPho",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e51e780-f6e5-48f8-ca1b-292aa93212bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRZm_OAbs3qA",
        "outputId": "13da94c5-5117-4aeb-a12f-27b73bc258e4",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAMzy_0FtaUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12efd1e1-a70b-44ac-e23c-2ffb46f0c687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from trl import SFTTrainer\n",
        "from peft import LoraConfig\n",
        "from datasets import load_dataset\n",
        "from transformers import (AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz3vMSzhs-P7"
      },
      "source": [
        "## Step 2: Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "rzRN0gc95T0n",
        "outputId": "46b8e59d-7f60-433c-9879-52c9d3f8bfbd",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "No GPU found. A GPU is needed for quantization.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-663633c1783d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m llama_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path = \"EthioNLP/Amharic-llama-base-model\",\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                             quantization_config = BitsAndBytesConfig(load_in_4bit = True,\n\u001b[1;32m      3\u001b[0m                                                             \u001b[0mbnb_4bit_compute_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"float16\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                             bnb_4bit_quant_type = \"nf4\"))\n\u001b[1;32m      5\u001b[0m \u001b[0mllama_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2295\u001b[0m                     \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2297\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No GPU found. A GPU is needed for quantization.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2298\u001b[0m                 logger.info(\n\u001b[1;32m   2299\u001b[0m                     \u001b[0;34m\"The device_map was not initialized.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No GPU found. A GPU is needed for quantization."
          ]
        }
      ],
      "source": [
        "llama_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path = \"EthioNLP/Amharic-llama-base-model\",\n",
        "                                                            quantization_config = BitsAndBytesConfig(load_in_4bit = True,\n",
        "                                                            bnb_4bit_compute_dtype = getattr(torch, \"float16\"),\n",
        "                                                            bnb_4bit_quant_type = \"nf4\"))\n",
        "llama_model.config.use_cache = False\n",
        "llama_model.config.pretraining_tp = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6aWb1e7tNRS"
      },
      "source": [
        "## Step 3: Loading the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVlXsHao5lWZ"
      },
      "outputs": [],
      "source": [
        "llama_tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path = \"EthioNLP/Amharic-llama-base-model\", trust_remote_code = True)\n",
        "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
        "llama_tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7mFW5bWWB09"
      },
      "outputs": [],
      "source": [
        "# Load Amharic QA dataset\n",
        "dataset = load_dataset(\"israel/AmharicQA\")\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "def format_data(dataset):\n",
        "    formatted_data = []\n",
        "    for entry in dataset:\n",
        "\n",
        "        question = entry.get('question', '')  # Extract question, default to empty string if not found\n",
        "        answer = entry.get('answers', '')  # Directly use 'answers' as it is a string\n",
        "        #context = entry.get('context', '')\n",
        "        # Format the entry to include both context and question with answer as the expected response\n",
        "        formatted_entry = {\n",
        "             'text': f\"<s>  [INST] {question} [/INST] {answer} </s>\"\n",
        "        }\n",
        "        formatted_data.append(formatted_entry)\n",
        "\n",
        "    return Dataset.from_list(formatted_data)\n",
        "\n",
        "# Format the dataset for both training and validation\n",
        "formatted_train_dataset = format_data(dataset['train'])\n",
        "formatted_val_dataset = format_data(dataset['validation'])\n",
        "formatted_test_dataset = format_data(dataset['test'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['test'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDt2iyK1GKf0",
        "outputId": "9a65385e-cadd-41fb-8895-f0a769a85be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'context': 'ንጉሡ ላሊበላ የሚለውን ስም ያገኘው፣ ሲወለድ በንቦች ስለተከበበ ነው። ላል ማለት ማር ማለት ሲሆን፤ ላሊበላ ማለትም -ላል ይበላል (ማር ይበላል) ማለት አንደሆነ ይነግራል።  ውቅር ቤተክርስቲያናቱን ንጉሡ ጠርቦ የስራቸው ከመላእክት እገዛ ጋር እንደሆነ በኢትዮጵያ ኦርቶዶክስ እምነት ተከታዮች ይነግራል። በ16ኛው ከፍለ ዘመን አውሮፓዊ ተጓዥ ላሊበላን ተመልክቶ «ያየሁትን ብናግር ማንም እንደኔ ካላየ በፍጹም አያምነኝም» ሲል ተናግሮ ነበር። በላሊበላ 11 ውቅር ዐብያተ ክርስቲያናት ያሉ ሲሆን ከነዚህም ውስጥ ቤተ ጊዮርጊስ (ባለ መስቀል ቅርፁ) ሲታይ ውሃልኩን የጠበቀ ይመስላል። ቤተ መድሃኔ ዓለም የተባለው ደግሞ ከሁሉም ትልቁ ነው። ላሊበላ (ዳግማዊ ኢየሩሳሌም) የገና በዓል ታህሳስ 29 በልዩ ሁኔታ ና ድምቀት ይከበራል፣ \"ቤዛ ኩሉ\" ተብሎ የሚጠራው በነግህ የሚደረገው ዝማሬ በዚሁ በዓል የሚታይ ልዩ ና ታላቅ ትዕይንት ነው።የሚደረገውም ከቅዳሴ በኋላ በቤተ ማርያም ሲሆን ከታች ባለ ነጭ ካባ ካህናት ከላይ ደግሞ ባለጥቁር ካብ ካህናት በቅዱስ ያሬድ ዜማ ቤዛ ኩሉ እያሉ ይዘምራሉ። 11ዱ የቅዱስ ላሊበላ ፍልፍል አብያተ ክርስቲያናት ቤተ መድሃኔ ዓለም፣ ቤተ ማርያም፣ ቤተ ደናግል፣ ቤተ መስቀል፣ ቤተ ደብረሲና፣ ቤተ ጎለጎታ፣ ቤተ አማኑኤል፣ ቤተ አባ ሊባኖስ፣ ቤተ መርቆሬዎስ፣ ቤተ ገብርኤል ወሩፋኤል፣ ቤተ ጊዮርጊስ ናቸው።', 'question': 'በላሊበላ ስንት ውቅር አብያተ ክርስቲያናት አሉ?', 'answers': '11'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'].to_pandas().head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "collapsed": true,
        "id": "STfkbBsa4VJ2",
        "outputId": "3bbc5081-4e54-4a75-8746-b3cba2e9997a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             context  \\\n",
              "0  ጠቅላይ ሚኒስትር ዐቢይ አሕመድ ከ2010 ጀምሮ በፋይናንሱ ዘርፍ ስኬታማ ...   \n",
              "1  ጠቅላይ ሚኒስትር ዐቢይ አሕመድ ከ2010 ጀምሮ በፋይናንሱ ዘርፍ ስኬታማ ...   \n",
              "2  ጠቅላይ ሚኒስትር ዐቢይ አሕመድ ከ2010 ጀምሮ በፋይናንሱ ዘርፍ ስኬታማ ...   \n",
              "3  67ኛው ግጥም በጃዝ ምሽት የፊታችን ረቡዕ ከምሽቱ 12 ሰዓት ጀምሮ በራስ...   \n",
              "4  67ኛው ግጥም በጃዝ ምሽት የፊታችን ረቡዕ ከምሽቱ 12 ሰዓት ጀምሮ በራስ...   \n",
              "5  67ኛው ግጥም በጃዝ ምሽት የፊታችን ረቡዕ ከምሽቱ 12 ሰዓት ጀምሮ በራስ...   \n",
              "6  67ኛው ግጥም በጃዝ ምሽት የፊታችን ረቡዕ ከምሽቱ 12 ሰዓት ጀምሮ በራስ...   \n",
              "7  67ኛው ግጥም በጃዝ ምሽት የፊታችን ረቡዕ ከምሽቱ 12 ሰዓት ጀምሮ በራስ...   \n",
              "8  በኢትዮጵያ አየር ኃይል ውስጥ ለ25 ዓመታት ያገለገሉት ብርጋዴር ጄነራል ...   \n",
              "9  በኢትዮጵያ አየር ኃይል ውስጥ ለ25 ዓመታት ያገለገሉት ብርጋዴር ጄነራል ...   \n",
              "\n",
              "                                            question  \\\n",
              "0      የታክስ ገቢ ከ2010-2012 በመቶኛ የምን ያህል መጠን እድገት አሳየ?   \n",
              "1               በ2010 የነበረው የታክስ ገቢ በ2012 ምን ያህል ሆነ?   \n",
              "2                     በ2010 ዓመታዊ የታክስ ገቢ ስንት ብር ነበር?   \n",
              "3                         67ኛው ግጥም በጃዝ የት ነው የሚካሄደው?   \n",
              "4            በ67ኛው ግጥም በጃዝ ምሽት ላይ ዲስኩር የሚያቀርቡት ማናቸው?   \n",
              "5          አቶ አበባው አያሌው በየት ዩኒቨርሲቲ የታሪክ መምህርነት ይሰራሉ?   \n",
              "6         አቶ አበባው አያሌው በአዲስ አበባ ዩኒቨርሲቲ የምን መምህር ናቸው?   \n",
              "7  በ67ኛው ግጥም በጃዝ ምሽት ላይ አርቲስት ሽመልስ አበራና እታፈራሁ መብራ...   \n",
              "8      ለተባበሩት መንግሥታት ድርጅት የደቡብ ሱዳን ሰላም ማስከበር ማን ተሾመ?   \n",
              "9               ብርጋዴር ጄነራል መአሾ ስዩም ከዚህ በፊት የት ሠርተዋል?   \n",
              "\n",
              "                                    answers  \n",
              "0                                   የ36 በመቶ  \n",
              "1                                  311 ቢሊየን  \n",
              "2                                  229 ቢሊየን  \n",
              "3                                   በራስ ሆቴል  \n",
              "4                              አቶ አበባው አያሌው  \n",
              "5                           በአዲስ አበባ ዩኒቨርሲቲ  \n",
              "6                                      የታሪክ  \n",
              "7                                  አጭር ተውኔት  \n",
              "8                    ብርጋዴር ጄነራል መአሾ ሀጎስ ስዩም  \n",
              "9  በተመድ የላይቤሪያ እንዲሁም ዳርፉር ሰላም አስከባሪ ኃይል ውስጥ  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b84d4b21-9502-47a4-9340-a0921f195e8e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ጠቅላይ ሚኒስትር ዐቢይ አሕመድ ከ2010 ጀምሮ በፋይናንሱ ዘርፍ ስኬታማ ...</td>\n",
              "      <td>የታክስ ገቢ ከ2010-2012 በመቶኛ የምን ያህል መጠን እድገት አሳየ?</td>\n",
              "      <td>የ36 በመቶ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ጠቅላይ ሚኒስትር ዐቢይ አሕመድ ከ2010 ጀምሮ በፋይናንሱ ዘርፍ ስኬታማ ...</td>\n",
              "      <td>በ2010 የነበረው የታክስ ገቢ በ2012 ምን ያህል ሆነ?</td>\n",
              "      <td>311 ቢሊየን</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ጠቅላይ ሚኒስትር ዐቢይ አሕመድ ከ2010 ጀምሮ በፋይናንሱ ዘርፍ ስኬታማ ...</td>\n",
              "      <td>በ2010 ዓመታዊ የታክስ ገቢ ስንት ብር ነበር?</td>\n",
              "      <td>229 ቢሊየን</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>67ኛው ግጥም በጃዝ ምሽት የፊታችን ረቡዕ ከምሽቱ 12 ሰዓት ጀምሮ በራስ...</td>\n",
              "      <td>67ኛው ግጥም በጃዝ የት ነው የሚካሄደው?</td>\n",
              "      <td>በራስ ሆቴል</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>67ኛው ግጥም በጃዝ ምሽት የፊታችን ረቡዕ ከምሽቱ 12 ሰዓት ጀምሮ በራስ...</td>\n",
              "      <td>በ67ኛው ግጥም በጃዝ ምሽት ላይ ዲስኩር የሚያቀርቡት ማናቸው?</td>\n",
              "      <td>አቶ አበባው አያሌው</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>67ኛው ግጥም በጃዝ ምሽት የፊታችን ረቡዕ ከምሽቱ 12 ሰዓት ጀምሮ በራስ...</td>\n",
              "      <td>አቶ አበባው አያሌው በየት ዩኒቨርሲቲ የታሪክ መምህርነት ይሰራሉ?</td>\n",
              "      <td>በአዲስ አበባ ዩኒቨርሲቲ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>67ኛው ግጥም በጃዝ ምሽት የፊታችን ረቡዕ ከምሽቱ 12 ሰዓት ጀምሮ በራስ...</td>\n",
              "      <td>አቶ አበባው አያሌው በአዲስ አበባ ዩኒቨርሲቲ የምን መምህር ናቸው?</td>\n",
              "      <td>የታሪክ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>67ኛው ግጥም በጃዝ ምሽት የፊታችን ረቡዕ ከምሽቱ 12 ሰዓት ጀምሮ በራስ...</td>\n",
              "      <td>በ67ኛው ግጥም በጃዝ ምሽት ላይ አርቲስት ሽመልስ አበራና እታፈራሁ መብራ...</td>\n",
              "      <td>አጭር ተውኔት</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>በኢትዮጵያ አየር ኃይል ውስጥ ለ25 ዓመታት ያገለገሉት ብርጋዴር ጄነራል ...</td>\n",
              "      <td>ለተባበሩት መንግሥታት ድርጅት የደቡብ ሱዳን ሰላም ማስከበር ማን ተሾመ?</td>\n",
              "      <td>ብርጋዴር ጄነራል መአሾ ሀጎስ ስዩም</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>በኢትዮጵያ አየር ኃይል ውስጥ ለ25 ዓመታት ያገለገሉት ብርጋዴር ጄነራል ...</td>\n",
              "      <td>ብርጋዴር ጄነራል መአሾ ስዩም ከዚህ በፊት የት ሠርተዋል?</td>\n",
              "      <td>በተመድ የላይቤሪያ እንዲሁም ዳርፉር ሰላም አስከባሪ ኃይል ውስጥ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b84d4b21-9502-47a4-9340-a0921f195e8e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b84d4b21-9502-47a4-9340-a0921f195e8e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b84d4b21-9502-47a4-9340-a0921f195e8e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c1cd5154-82dc-4643-9c6e-e15c83226610\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1cd5154-82dc-4643-9c6e-e15c83226610')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c1cd5154-82dc-4643-9c6e-e15c83226610 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset['train']\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\\u1320\\u1245\\u120b\\u12ed \\u121a\\u1292\\u1235\\u1275\\u122d \\u12d0\\u1262\\u12ed \\u12a0\\u1215\\u1218\\u12f5 \\u12a82010 \\u1300\\u121d\\u122e \\u1260\\u134b\\u12ed\\u1293\\u1295\\u1231 \\u12d8\\u122d\\u134d \\u1235\\u12ac\\u1273\\u121b \\u1208\\u12cd\\u1326\\u127d \\u1218\\u1218\\u12dd\\u1308\\u1263\\u1278\\u12cd\\u1295 \\u1308\\u1208\\u1339\\u1361\\u1361 \\u1320\\u1245\\u120b\\u12ed \\u121a\\u1292\\u1235\\u1275\\u122d \\u12d0\\u1262\\u12ed \\u12e8\\u134b\\u12ed\\u1293\\u1295\\u1235 \\u12d8\\u122d\\u134d \\u12d0\\u1260\\u12ed\\u1275 \\u1235\\u12ac\\u1276\\u127d \\u1260\\u121a\\u120d \\u1260\\u121b\\u1205\\u1260\\u122b\\u12ca \\u1275\\u1235\\u1235\\u122d \\u1308\\u1343\\u1278\\u12cd \\u120b\\u12ed \\u12a5\\u1295\\u12f3\\u1235\\u1273\\u12c8\\u1241\\u1275 \\u12e8\\u1273\\u12ad\\u1235 \\u1308\\u1262 \\u12602010 \\u12a8\\u1290\\u1260\\u1228\\u1260\\u1275 229 \\u1262\\u120a\\u12e8\\u1295 \\u1265\\u122d \\u12602012 \\u12e836 \\u1260\\u1218\\u1276 \\u132d\\u121b\\u122a \\u1260\\u121b\\u1233\\u12e8\\u1275 311 \\u1262\\u120a\\u12e8\\u1295 \\u121b\\u12f5\\u1228\\u1235 \\u1270\\u127d\\u120f\\u120d\\u1362\",\n          \"67\\u129b\\u12cd \\u130d\\u1325\\u121d \\u1260\\u1303\\u12dd \\u121d\\u123d\\u1275 \\u12e8\\u134a\\u1273\\u127d\\u1295 \\u1228\\u1261\\u12d5 \\u12a8\\u121d\\u123d\\u1271 12 \\u1230\\u12d3\\u1275 \\u1300\\u121d\\u122e \\u1260\\u122b\\u1235 \\u1206\\u1274\\u120d \\u12ed\\u12ab\\u1204\\u12f3\\u120d\\u1361\\u1361 \\u12a0\\u1295\\u130b\\u134e\\u1279 \\u1308\\u1323\\u121a\\u12eb\\u1295 \\u1290\\u1262\\u12ed \\u1218\\u12ae\\u1295\\u1295\\u1363 \\u1270\\u1348\\u122a \\u12a0\\u1208\\u1219\\u1363 \\u12f6/\\u122d \\u1219\\u1209\\u12a0\\u1208\\u121d \\u1270\\u1308\\u129d\\u12c8\\u122d\\u1245\\u1363 \\u1218\\u122d\\u12f5 \\u1270\\u1235\\u134b\\u12ec\\u1293 \\u1264\\u12db \\u1275\\u12d5\\u12db\\u12d9 \\u12e8\\u130d\\u1325\\u121d \\u1235\\u122b\\u12ce\\u127b\\u1278\\u12cd\\u1295 \\u12e8\\u121a\\u12eb\\u1240\\u122d\\u1261 \\u1232\\u1206\\u1295 \\u12a0\\u122d\\u1272\\u1235\\u1275 \\u123d\\u1218\\u120d\\u1235 \\u12a0\\u1260\\u122b\\u1293 \\u12a5\\u1273\\u1348\\u122b\\u1201 \\u1218\\u1265\\u122b\\u1271 \\u12a0\\u132d\\u122d \\u1270\\u12cd\\u1294\\u1275 \\u12eb\\u1240\\u122d\\u1263\\u1209 \\u1270\\u1265\\u120f\\u120d\\u1361\\u1361 \\u1260\\u12a0\\u12f2\\u1235 \\u12a0\\u1260\\u1263 \\u12e9\\u1292\\u1268\\u122d\\u1232\\u1272 \\u12e8\\u1273\\u122a\\u12ad \\u121d\\u1201\\u122d \\u12e8\\u1206\\u1291\\u1275 \\u12a0\\u1276 \\u12a0\\u1260\\u1263\\u12cd \\u12a0\\u12eb\\u120c\\u12cd \\u12f2\\u1235\\u12a9\\u122d \\u12a5\\u1295\\u12f0\\u121a\\u12eb\\u1240\\u122d\\u1261 \\u1273\\u12cd\\u124b\\u120d\\u1361\\u1361\",\n          \"\\u1260\\u12a2\\u1275\\u12ee\\u1335\\u12eb \\u12a0\\u12e8\\u122d \\u1283\\u12ed\\u120d \\u12cd\\u1235\\u1325 \\u120825 \\u12d3\\u1218\\u1273\\u1275 \\u12eb\\u1308\\u1208\\u1308\\u1209\\u1275 \\u1265\\u122d\\u130b\\u12f4\\u122d \\u1304\\u1290\\u122b\\u120d \\u1218\\u12a0\\u123e \\u1200\\u130e\\u1235 \\u1235\\u12e9\\u121d \\u12e8\\u1270\\u1263\\u1260\\u1229\\u1275 \\u1218\\u1295\\u130d\\u1235\\u1273\\u1275 \\u12f5\\u122d\\u1305\\u1275 \\u12e8\\u12f0\\u1261\\u1265 \\u1231\\u12f3\\u1295 \\u1230\\u120b\\u121d \\u121b\\u1235\\u12a8\\u1260\\u122d \\u1270\\u120d\\u12a5\\u12ae \\u12a0\\u12db\\u12e5 \\u1206\\u1290\\u12cd \\u1270\\u1230\\u12e8\\u1219\\u1362 \\u1265\\u122d\\u130b\\u12f4\\u12e8\\u122d \\u1304\\u1290\\u122b\\u120d \\u1218\\u12a0\\u123e\\u00a0 \\u1260\\u1270\\u1218\\u12f5 \\u12e8\\u120b\\u12ed\\u1264\\u122a\\u12eb \\u12a5\\u1295\\u12f2\\u1201\\u121d \\u12f3\\u122d\\u1349\\u122d \\u1230\\u120b\\u121d \\u12a0\\u1235\\u12a8\\u1263\\u122a \\u1283\\u12ed\\u120d \\u12cd\\u1235\\u1325 \\u121b\\u1308\\u120d\\u1308\\u120b\\u1278\\u12cd\\u121d \\u1273\\u12cd\\u124b\\u120d\\u1362 \\u12a0\\u12f2\\u1231\\u1295 \\u1239\\u1218\\u1275 \\u12a8\\u1325\\u122d 04 \\u1240\\u1295 2013 \\u12d3.\\u121d \\u1300\\u121d\\u122e \\u12a5\\u1295\\u12f0\\u1270\\u1230\\u1323\\u1278\\u12cd\\u121d \\u1260\\u1270\\u1218\\u12f5 \\u1218\\u1228\\u1303 \\u120b\\u12ed \\u1270\\u1308\\u120d\\u133f\\u120d\\u1362\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u1208\\u1270\\u1263\\u1260\\u1229\\u1275 \\u1218\\u1295\\u130d\\u1225\\u1273\\u1275 \\u12f5\\u122d\\u1305\\u1275 \\u12e8\\u12f0\\u1261\\u1265 \\u1231\\u12f3\\u1295 \\u1230\\u120b\\u121d \\u121b\\u1235\\u12a8\\u1260\\u122d \\u121b\\u1295 \\u1270\\u123e\\u1218?\",\n          \"\\u12602010 \\u12e8\\u1290\\u1260\\u1228\\u12cd \\u12e8\\u1273\\u12ad\\u1235 \\u1308\\u1262 \\u12602012 \\u121d\\u1295 \\u12eb\\u1205\\u120d \\u1206\\u1290?\",\n          \"\\u12a0\\u1276 \\u12a0\\u1260\\u1263\\u12cd \\u12a0\\u12eb\\u120c\\u12cd \\u1260\\u12e8\\u1275 \\u12e9\\u1292\\u1268\\u122d\\u1232\\u1272 \\u12e8\\u1273\\u122a\\u12ad \\u1218\\u121d\\u1205\\u122d\\u1290\\u1275 \\u12ed\\u1230\\u122b\\u1209?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u1265\\u122d\\u130b\\u12f4\\u122d \\u1304\\u1290\\u122b\\u120d \\u1218\\u12a0\\u123e \\u1200\\u130e\\u1235 \\u1235\\u12e9\\u121d\",\n          \"311 \\u1262\\u120a\\u12e8\\u1295\",\n          \"\\u1260\\u12a0\\u12f2\\u1235 \\u12a0\\u1260\\u1263 \\u12e9\\u1292\\u1268\\u122d\\u1232\\u1272\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg0l8oes933f",
        "outputId": "6597474f-c2a4-41ba-f9b2-aaa28e78e52e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['context', 'question', 'answers'],\n",
              "        num_rows: 1723\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['context', 'question', 'answers'],\n",
              "        num_rows: 595\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['context', 'question', 'answers'],\n",
              "        num_rows: 299\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataset to a pandas DataFrame\n",
        "df = dataset['validation'].to_pandas()\n",
        "\n",
        "# Slice the DataFrame to get rows from index 10 to 20\n",
        "print(df[10:21])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0xqAbs_9uYq",
        "outputId": "e14e97e7-3d2e-4316-8c08-a000976aa71d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              context  \\\n",
            "10  ኬንያ የኬንያ ሪፐብሊክ በምስራቅ አፍሪካ የምትገኝ ሀገር ናት። በሰሜን ከ...   \n",
            "11  ኬንያ የኬንያ ሪፐብሊክ በምስራቅ አፍሪካ የምትገኝ ሀገር ናት። በሰሜን ከ...   \n",
            "12  ኬንያ የኬንያ ሪፐብሊክ በምስራቅ አፍሪካ የምትገኝ ሀገር ናት። በሰሜን ከ...   \n",
            "13  ኬንያ የኬንያ ሪፐብሊክ በምስራቅ አፍሪካ የምትገኝ ሀገር ናት። በሰሜን ከ...   \n",
            "14  ኬንያ የኬንያ ሪፐብሊክ በምስራቅ አፍሪካ የምትገኝ ሀገር ናት። በሰሜን ከ...   \n",
            "15  ኬንያ የኬንያ ሪፐብሊክ በምስራቅ አፍሪካ የምትገኝ ሀገር ናት። በሰሜን ከ...   \n",
            "16  ውትድርና  የናይጄሪያ ጦር ሠራዊት ሀገሯን የመከላከል፣ የሀገሯን ፍላጎት ...   \n",
            "17  ውትድርና  የናይጄሪያ ጦር ሠራዊት ሀገሯን የመከላከል፣ የሀገሯን ፍላጎት ...   \n",
            "18  ውትድርና  የናይጄሪያ ጦር ሠራዊት ሀገሯን የመከላከል፣ የሀገሯን ፍላጎት ...   \n",
            "19  ውትድርና  የናይጄሪያ ጦር ሠራዊት ሀገሯን የመከላከል፣ የሀገሯን ፍላጎት ...   \n",
            "20  ውትድርና  የናይጄሪያ ጦር ሠራዊት ሀገሯን የመከላከል፣ የሀገሯን ፍላጎት ...   \n",
            "\n",
            "                                        question             answers  \n",
            "10                ኬንያ ከእንግሊዝ ቅኝ ግዛት የወጣችው መቼ ነው?  በዲሴምበር 1963 እ.ኤ.አ.  \n",
            "11                        ኬንያን ቅኝ የገዛቻት ሀገር ማናት?               ብሪታንያ  \n",
            "12          የኬንያ ሕገ መንግሥት በሕዝበ ውሳኔ የተሻሻለው መቼ ነው?   በኦገስት 2010 እ.ኤ.አ.  \n",
            "13              ኬንያ በስንት የአስተዳደር ክልሎች የተከፈለች ናት?                 በ፵፯  \n",
            "14                    ኬንያ ስንት የአስተዳደር ክልሎች አሏት?                   ፵፯  \n",
            "15                              የኬንያ ዋና መዲና ማናት?                ናይሮቢ  \n",
            "16  የናይጄሪያ ሰራዊት ሰላም ለማስከበር ወደ ላይቤሪያ የገባው መች ነበር?         1997 እ.ኤ.አ.  \n",
            "17       ናይጄሪያ ለዓለም ከምታቀርባቸው ምርቶች ዋነኞቹ የትኞቹ ናቸው?            ካካውና ጎማ   \n",
            "18   ናይጄሪያ ለዓለም ገበያ በምታቀርበው የፔትሮሊየም ምርት ስንተኛ ናት?                 12ኛ  \n",
            "19                        የናይጄሪያ የቆዳ ስፋት ስንት ነው?     923,768 ካሬ ኪ.ሚ.  \n",
            "20         ናይጄሪያ በቆዳ ስፋት ከዓለም ስንተኛ ደረጃ ላይ ትገኛለች?                 ፴፪ኛ  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect a sample entry\n",
        "print(dataset['train'][7])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ljLXks93L8u",
        "outputId": "d517d125-7279-4afb-e949-11cad9e7b109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'context': '67ኛው ግጥም በጃዝ ምሽት የፊታችን ረቡዕ ከምሽቱ 12 ሰዓት ጀምሮ በራስ ሆቴል ይካሄዳል፡፡ አንጋፎቹ ገጣሚያን ነቢይ መኮንን፣ ተፈሪ አለሙ፣ ዶ/ር ሙሉአለም ተገኝወርቅ፣ መርድ ተስፋዬና ቤዛ ትዕዛዙ የግጥም ስራዎቻቸውን የሚያቀርቡ ሲሆን አርቲስት ሽመልስ አበራና እታፈራሁ መብራቱ አጭር ተውኔት ያቀርባሉ ተብሏል፡፡ በአዲስ አበባ ዩኒቨርሲቲ የታሪክ ምሁር የሆኑት አቶ አበባው አያሌው ዲስኩር እንደሚያቀርቡ ታውቋል፡፡', 'question': 'በ67ኛው ግጥም በጃዝ ምሽት ላይ አርቲስት ሽመልስ አበራና እታፈራሁ መብራቱ ምን ያቀርባሉ ተብሎ ይጠበቃል?', 'answers': 'አጭር ተውኔት'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some examples from the formatted dataset\n",
        "for example in formatted_train_dataset:\n",
        "    print(example['text'])\n",
        "    break  # Just print one example for inspection\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39xLRDEzHIb3",
        "outputId": "f64e8d8c-9645-45c9-e9a5-f2f92bf07f68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>  [INST] የታክስ ገቢ ከ2010-2012 በመቶኛ የምን ያህል መጠን እድገት አሳየ? [/INST] የ36 በመቶ </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coUlIR-ytjiF"
      },
      "source": [
        "## Step 4: Setting the training arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWhXvTzuI8sg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    # Compute the predicted labels by taking the argmax of the logits\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Flatten the arrays to make sure we are comparing element-wise\n",
        "    predictions = predictions.flatten()\n",
        "    labels = labels.flatten()\n",
        "\n",
        "    # Calculate the accuracy\n",
        "    correct = np.sum(predictions == labels)\n",
        "    accuracy = correct / len(labels)\n",
        "\n",
        "    return {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
      ],
      "metadata": {
        "id": "08bSDv41VHOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJXpOgBFuSrc",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"./results\",                  # Directory to save model checkpoints\n",
        "    per_device_train_batch_size=2,           # Smaller batch size due to the larger LLaMA model size\n",
        "    per_device_eval_batch_size=2,            # Evaluation batch size\n",
        "    gradient_accumulation_steps=16,           # Accumulate gradients to simulate a larger batch size\n",
        "    num_train_epochs=4,                      # Number of training epochs 5 is better\n",
        "    learning_rate=3e-5,                      # Lower learning rate for fine-tuning\n",
        "    warmup_steps=100,                       # Warmup steps to stabilize training\n",
        "    weight_decay=0.01,                       # Regularization to prevent overfitting\n",
        "    logging_dir='./logs',                    # Directory to store logs\n",
        "    logging_steps=50,                       # Log every 100 steps\n",
        "    evaluation_strategy=\"steps\",             # Evaluate model periodically\n",
        "    eval_steps=100,                         # Evaluation frequency\n",
        "    save_steps=100,                         # Save model checkpoint frequency\n",
        "    save_total_limit=1,                      # Only keep the last two checkpoints\n",
        "    fp16=True,                               # Use mixed precision to speed up training\n",
        "    load_best_model_at_end=True,             # Load the best model after training is complete\n",
        "    metric_for_best_model=\"eval_loss\",       # Use evaluation loss to determine the best model\n",
        "    greater_is_better=False,                 # Lower evaluation loss indicates a better model\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RGLZtFwHQiZ"
      },
      "source": [
        "## Step 5: Creating the Supervised Fine-Tuning trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "0bb971d46c5f43baaa369e8cf9f42a6c",
            "6b171419c1004259b237ee51d2388396",
            "795430ae4931467da219d86a02c91c6c",
            "94aee70b443a44bb8f097442fc4a67af",
            "a813be4bf7454cd3969c39ce8f5d920b",
            "feda9e5c0751447485b0b562d28da2b8",
            "f2d73faaecf3400bb98df686886465f8",
            "02be99b85b234526a6d5a5d60deee14c",
            "e2ff98b438a94bd59c9209e03066f445",
            "07391df100304ec89da591ffa2a34bed",
            "618a882522664c6888b7c0a6aaba1152",
            "06233f7b8b4348c39b657f0511e80198",
            "5d82e1110f414a8eaea7fc3758020e0c",
            "0345d9676b024589916a74b4405d1115",
            "5c30b816ba6b4affbc6bbca7fa2b8a18",
            "e054372ce3e944089558741895912cf4",
            "201e44bd846f4b65a8ff37c7cf2a5c9d",
            "57fa33d63de64a15808f73a7c8655bb9",
            "eca1287f3c664545b067d543d8dffc8d",
            "c5043f7ed4124dc19a27f50e2dbba2ed",
            "82599d1dcf3b4661bc8862cce4f26455",
            "9e08f2e934d2451fba6cdd510e9d24a4"
          ]
        },
        "id": "0yiTXT1m5rz6",
        "outputId": "c11852b2-2657-418c-c744-1b548be62241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1723 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bb971d46c5f43baaa369e8cf9f42a6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/595 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06233f7b8b4348c39b657f0511e80198"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:427: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "llama_sft_trainer = SFTTrainer(model = llama_model,\n",
        "                               args = training_arguments,\n",
        "                               train_dataset=formatted_train_dataset,\n",
        "                               eval_dataset=formatted_val_dataset,\n",
        "                               compute_metrics=compute_metrics,\n",
        "                               tokenizer = llama_tokenizer,\n",
        "                               peft_config = LoraConfig(task_type = \"CAUSAL_LM\", r = 32, lora_alpha = 16, lora_dropout = 0.1),\n",
        "                               dataset_text_field = \"text\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSF8SHFKt1xL"
      },
      "source": [
        "## Step 6: Training the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "y0V3Y5fAUW_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "oNAWrsSWaSXj",
        "outputId": "1113eedf-92be-41a8-a9dc-b962a0639c38"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:1301: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  new_forward = torch.cuda.amp.autocast(dtype=torch.float16)(model_forward_func)\n",
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='78' max='212' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 78/212 15:09 < 26:43, 0.08 it/s, Epoch 1.43/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='81' max='212' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 81/212 15:46 < 26:08, 0.08 it/s, Epoch 1.48/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "llama_sft_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llama_sft_trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "flM_MFcq3S7c",
        "outputId": "f579fa87-7974-4f64-91cb-d5a53fca2606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='149' max='149' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [149/149 00:53]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 3.1389849185943604,\n",
              " 'eval_runtime': 54.028,\n",
              " 'eval_samples_per_second': 11.013,\n",
              " 'eval_steps_per_second': 2.758,\n",
              " 'epoch': 4.92}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llama_sft_trainer.evaluate()"
      ],
      "metadata": {
        "id": "Xperxsv3-vgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "llama_sft_trainer.save_model(\"./fine_tuned_llama_model\")\n"
      ],
      "metadata": {
        "id": "75-300OwydNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model\n",
        "#llama_model = AutoModelForCausalLM.from_pretrained(\"./fine_tuned_llama_model\")\n",
        "#llama_tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_llama_model\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ut11fQLsymOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMPw6WU6vbjP"
      },
      "source": [
        "## Step 7: Chatting with the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import pipeline\n",
        "# def chat_with_model(question):\n",
        "#     # Format the question for the model\n",
        "#     user_prompt = f\"<s>[INST] {question} [/INST]\"\n",
        "\n",
        "#     # Initialize the pipeline\n",
        "#     text_generation_pipeline = pipeline(task=\"text-generation\", model=llama_model, tokenizer=llama_tokenizer, max_length=100)\n",
        "\n",
        "#     # Generate the answer\n",
        "#     model_answer = text_generation_pipeline(user_prompt)\n",
        "\n",
        "#     # Extract the generated text\n",
        "#     answer = model_answer[0]['generated_text']\n",
        "\n",
        "#     # Print the answer\n",
        "#     print(answer)\n",
        "\n"
      ],
      "metadata": {
        "id": "zIeNAAigE3kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Evaluating the model on the Test Dataset"
      ],
      "metadata": {
        "id": "lUTRzkanGcZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " def evaluate_on_test_data():\n",
        "    correct = 0\n",
        "    total = len(formatted_test_dataset)\n",
        "    predictions = []\n",
        "\n",
        "    for example in formatted_test_dataset:\n",
        "        question = example['text'].split(\"[INST]\")[1].split(\"[/INST]\")[0].strip()\n",
        "        true_answer = example['text'].split(\"[/INST]\")[1].strip()\n",
        "\n",
        "        # Generate the answer using the model\n",
        "        generated_answer = chat_with_model(question)\n",
        "        predictions.append(generated_answer)\n",
        "        # # Print the results\n",
        "        # print(f\"Question: {question}\")\n",
        "        # print(f\"Generated Answer: {generated_answer}\")\n",
        "        # print(f\"True Answer: {true_answer}\")\n",
        "        # print(\"-\" * 50)\n",
        "\n",
        "        # Check if the generated answer matches the true answer (you might need a more robust matching technique)\n",
        "        if generated_answer.strip() == true_answer.strip():\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "CJ4M3hOlGZaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pridictions = evaluate_on_test_data()"
      ],
      "metadata": {
        "id": "UDUZ9dKAnN-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from transformers import pipeline\n",
        "\n",
        "# Function to clean and truncate the generated text after encountering unwanted content\n",
        "def clean_and_truncate_text(text):\n",
        "    # Remove any special tokens like [INST], [/INST], etc.\n",
        "    cleaned_text = re.sub(r\"\\[.*?\\]\", \"\", text)  # Remove square-bracket content\n",
        "    cleaned_text = cleaned_text.replace(\"</s>\", \"\")  # Remove any leftover closing tag\n",
        "    cleaned_text = cleaned_text.strip()  # Remove leading/trailing whitespace\n",
        "\n",
        "    # Split the text and only keep the part before repetitive content or newlines\n",
        "    truncated_text = cleaned_text.split('\\n')[0]  # Split by newline and take the first line\n",
        "    truncated_text = truncated_text.split('----')[0]  # Stop at the first '----' if it appears\n",
        "    return truncated_text.strip()  # Return cleaned and truncated text\n",
        "\n",
        "# Function to generate the model's response and print only the question and the first valid answer\n",
        "def chat_with_model(question):\n",
        "    # Format the question for the model\n",
        "    user_prompt = f\"<s>[INST] {question} [/INST]\"\n",
        "\n",
        "    # Initialize the text generation pipeline\n",
        "    text_generation_pipeline = pipeline(task=\"text-generation\", model=llama_model, tokenizer=llama_tokenizer, max_length=100)\n",
        "\n",
        "    # Generate the answer from the model\n",
        "    model_answer = text_generation_pipeline(user_prompt)\n",
        "    generated_answer = model_answer[0]['generated_text']\n",
        "\n",
        "    # Clean and truncate the generated answer\n",
        "    cleaned_generated_answer = clean_and_truncate_text(generated_answer)\n",
        "\n",
        "    # # Print both the question and the cleaned answer\n",
        "    # print(f\"Question: {question}\")\n",
        "    # print(f\"Generated Answer: {cleaned_generated_answer}\")\n",
        "    # print(\"-\" * 50)  # Separator for readability\n",
        "\n",
        "    return cleaned_generated_answer"
      ],
      "metadata": {
        "id": "Y7dxuhAy5zFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  import re\n",
        "#  from transformers import pipeline\n",
        "# def chat_with_model(question):\n",
        "#     # Format the question for the model\n",
        "#     user_prompt = f\"<s>[INST] {question} [/INST]\"\n",
        "\n",
        "#     # Initialize the pipeline\n",
        "#     text_generation_pipeline = pipeline(task=\"text-generation\", model=llama_model, tokenizer=llama_tokenizer, max_length=100)\n",
        "\n",
        "#     # Generate the answer\n",
        "#     model_answer = text_generation_pipeline(user_prompt)\n",
        "\n",
        "#     # Extract the generated text and clean it\n",
        "#     answer = model_answer[0]['generated_text'].split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "#     return answer  # Return the generated answer instead of just printing it\n"
      ],
      "metadata": {
        "id": "oYnIC8NxHrYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_on_test_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ThyW5ai0G9Z-",
        "outputId": "32d5ff28-de69-42a6-e3b7-a666ddb9968f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: በላሊበላ ስንት ውቅር አብያተ ክርስቲያናት አሉ?\n",
            "Generated Answer: <s> በላሊበላ ስንት ውቅር አብያተ ክርስቲያናት አሉ?  79\n",
            "True Answer: 11 </s>\n",
            "--------------------------------------------------\n",
            "Question: ከላሊበላ አስራ አንዱ ውቅር አብያተ ክርስቲያናት ግዙፉ የትኛው ነው?\n",
            "Generated Answer: <s> ከላሊበላ አስራ አንዱ ውቅር አብያተ ክርስቲያናት ግዙፉ የትኛው ነው?  የቅዱስ ጊዮርጊስ ቤተ ክርስቲያን\n",
            "True Answer: ቤተ መድሃኔ ዓለም </s>\n",
            "--------------------------------------------------\n",
            "Question: ከላሊበላ አስራ አንዱ ውቅር አብያተ ክርስቲያናት ቤተ ጊዮርጊስ ምን ዓይነት ቅርፅ አለው?\n",
            "Generated Answer: <s> ከላሊበላ አስራ አንዱ ውቅር አብያተ ክርስቲያናት ቤተ ጊዮርጊስ ምን ዓይነት ቅርፅ አለው?  ክብ ቅርጽ ያለው\n",
            "True Answer: መስቀል </s>\n",
            "--------------------------------------------------\n",
            "Question: ከላሊበላ አስራ አንዱ ውቅር አብያተ ክርስቲያናት የመስቀል ቅርጽ ያለው የትኛው ነው?\n",
            "Generated Answer: <s> ከላሊበላ አስራ አንዱ ውቅር አብያተ ክርስቲያናት የመስቀል ቅርጽ ያለው የትኛው ነው?  የቅዱስ ጊዮርጊስ ቤተ ክርስቲያን\n",
            "True Answer: ቤተ ጊዮርጊስ </s>\n",
            "--------------------------------------------------\n",
            "Question: በላሊበላ የጌታ ልደት ቀን በልዩ ሁኔታ የሚዘመረው ቤዛ ኵሉ የተሰኘው ዝማሬ የሚቀርበው በየትኛው ቤተ መቅደስ ነው?\n",
            "Generated Answer: <s> በላሊበላ የጌታ ልደት ቀን በልዩ ሁኔታ የሚዘመረው ቤዛ ኵሉ የተሰኘው ዝማሬ የሚቀርበው በየትኛው ቤተ መቅደስ ነው?  በዴቫ ቤተ-መቅደስ\n",
            "True Answer: በቤተ ማርያም </s>\n",
            "--------------------------------------------------\n",
            "Question: በላሊበላ የጌታ ልደት ቀን በቤተ ማርያም የሚቀርበው ልዩ ዝማሬ ምን ይባላል?\n",
            "Generated Answer: <s> በላሊበላ የጌታ ልደት ቀን በቤተ ማርያም የሚቀርበው ልዩ ዝማሬ ምን ይባላል?  ዘማሪነት\n",
            "True Answer: ቤዛ ኩሉ </s>\n",
            "--------------------------------------------------\n",
            "Question: አዲስ አበባ የሚለውን ስም ለከተማዋ የሰጡት ማናቸው?\n",
            "Generated Answer: <s> አዲስ አበባ የሚለውን ስም ለከተማዋ የሰጡት ማናቸው?\n",
            "True Answer: እቴጌ ጣይቱ </s>\n",
            "--------------------------------------------------\n",
            "Question: እቴጌ ጣይቱ አዲስ አበባ የሚለውን ስም ለከተማዋ የሰጡት መች ነበር?\n",
            "Generated Answer: <s> እቴጌ ጣይቱ አዲስ አበባ የሚለውን ስም ለከተማዋ የሰጡት መች ነበር?  በ1908 ዓ.ም\n",
            "True Answer: ኅዳር ፲፬ ቀን ፲፰፻፸፱ (1879) ዓ.ም. </s>\n",
            "--------------------------------------------------\n",
            "Question: አዲስ አበባ የኢትዮጵያ ምንድን ናት?\n",
            "Generated Answer: <s> አዲስ አበባ የኢትዮጵያ ምንድን ናት?  የኢትዮጵያ ዋና ከተማ\n",
            "True Answer: ዋና ከተማ </s>\n",
            "--------------------------------------------------\n",
            "Question: የአፍሪካ ሕብረት መቀመጫ መዲና ማናት?\n",
            "Generated Answer: <s> የአፍሪካ ሕብረት መቀመጫ መዲና ማናት?  አዲስ አበባ\n",
            "True Answer: አዲስ አበባ </s>\n",
            "--------------------------------------------------\n",
            "Question: የኢትዮጵያ ዋና መዲና ማናት?\n",
            "Generated Answer: <s> የኢትዮጵያ ዋና መዲና ማናት?  አዲስ አበባ\n",
            "True Answer: አዲስ አበባ </s>\n",
            "--------------------------------------------------\n",
            "Question: በኢትዮጵያ ከባህር ጠለል 2500 ሜትር ከፍታ የምትገኝ እንዲሁም በሀገሪቱ ትልቋ ከተማ ማን ትባላለች?\n",
            "Generated Answer: <s> በኢትዮጵያ ከባህር ጠለል 2500 ሜትር ከፍታ የምትገኝ እንዲሁም በሀገሪቱ ትልቋ ከተማ ማን ትባላለች?  ባህር ዳር ን።\n",
            "True Answer: አዲስ አበባ </s>\n",
            "--------------------------------------------------\n",
            "Question: አዲስ አበባ ከተማ ከባህር ጠለል በምን ያህል ከፍታ ትገኛለች?\n",
            "Generated Answer: <s> አዲስ አበባ ከተማ ከባህር ጠለል በምን ያህል ከፍታ ትገኛለች?  ከ864 ሜትር\n",
            "True Answer: በ2500 ሜትር </s>\n",
            "--------------------------------------------------\n",
            "Question: አዲስ አበባ የተቆረቆረችው ማን በመረጠው ቦታ ነው?\n",
            "Generated Answer: <s> አዲስ አበባ የተቆረቆረችው ማን በመረጠው ቦታ ነው?  በ1886 ዓ.ም.\n",
            "True Answer: እቴጌ ጣይቱ </s>\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-8a59e0efffe7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_on_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-26dfee89872a>\u001b[0m in \u001b[0;36mevaluate_on_test_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Generate the answer using the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mgenerated_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_with_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Print the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-cbad7f8f03ba>\u001b[0m in \u001b[0;36mchat_with_model\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Generate the answer from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmodel_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_generation_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mgenerated_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_answer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generated_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m               \u001b[0mids\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \"\"\"\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_long_generation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1120\u001b[0m             )\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1026\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# BS x SL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m             \u001b[0;31m# 11. run greedy search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1538\u001b[0;31m             return self.greedy_search(\n\u001b[0m\u001b[1;32m   1539\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m                 \u001b[0;31m# stop when each sentence is finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0munfinished_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m                     \u001b[0mthis_peer_finished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # You can also test with specific positions in the training data\n",
        "# specific_positions = [0, 10, 20]  # Indices of the questions you want to chat with\n",
        "# for pos in specific_positions:\n",
        "#     question = dataset['train'][pos]['question']  # Access the question text\n",
        "#     actual_answer = dataset['train'][pos]['answers']  # Access the actual answer\n",
        "#     chat_with_model(question, actual_answer)"
      ],
      "metadata": {
        "id": "cxJ2QF8J6F-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question\n",
        "chat_with_model(\"አቶ አበባው አያሌው በየት ዩኒቨርሲቲ የታሪክ መምህርነት ይሰራሉ?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1caJ9h6cVu4V",
        "outputId": "cf8bc856-ed01-4df5-a854-c9c9ccb17818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] አቶ አበባው አያሌው በየት ዩኒቨርሲቲ የታሪክ መምህርነት ይሰራሉ? [/INST] በአዲስ አበባ ዩኒቨርሲቲ  አቶ አበባው አያሌው በአዲስ አበባ ዩኒቨርሲቲ የታሪክ መምህርነት ተቀጥረው  ላለፉት 20 ዓመታት ሲያገለግሉ  ነበር።  አቶ አበባው በአዲስ አበባ ዩኒቨርሲቲ የታሪክ ትምህርት ክፍል ኃላፊ ሆነው  ላለፉት 10 ዓመታት  ሲያገለግሉ  ነበር።  አቶ አበባው በአዲስ አበባ ዩኒቨርሲቲ የታሪክ ትምህርት ክፍል ኃላፊ ሆነው  ላለፉት 10 ዓመታት  ሲያገለግሉ  ነበር።  አቶ አበባው በአዲስ አበባ ዩኒቨርሲቲ የታሪክ ትምህርት ክፍል ኃላፊ ሆነው  ላለፉት 10 ዓመታት  ሲያገለግሉ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question\n",
        "chat_with_model(\"አቶ አበባው አያሌው\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYLh9KcLV7EQ",
        "outputId": "9701fdce-8514-453e-9a5f-ce20adabb4d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] አቶ አበባው አያሌው [/INST] የኢትዮጵያ ታሪክ አጥኚ እና መምህር ናቸው? [/INST]   አዎ   አቶ አበባው አያሌው   [/ስተር]   አቶ አበባው አያሌው   [/ስተር]   አቶ አበባው አያሌው   [/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question\n",
        "chat_with_model(\"አትሌት ኃይሌ ገብረሥላሴ ለኢትዮጵያ የልብ ሕሙማን ስንት ብር ለመለገስ ቃል ገባ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "X0diGSbWXZ48",
        "outputId": "6c2bbb47-abc0-4a94-8417-10ae30c4da82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> አትሌት ኃይሌ ገብረሥላሴ ለኢትዮጵያ የልብ ሕሙማን ስንት ብር ለመለገስ ቃል ገባ?  1 ሚሊዮን ብር'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "access_token = \"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\"\n",
        "\n",
        "login(token=access_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGa5JkYdK2yk",
        "outputId": "c969ebf5-47b9-43aa-ddd3-ca485534d4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save only the PEFT fine-tuned weights from the trainer\n",
        "llama_sft_trainer.model.save_pretrained(\"/content/drive/MyDrive/peft_model\")"
      ],
      "metadata": {
        "id": "AFVI-xG-vzK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llama_sft_trainer.model.push_to_hub(\"lifecont/Llava_Am_chatbot\", token = access_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "ab314f6218d145b5885f91fa942f1e38",
            "50e20b7357fa48b3969587e3e87e2c1d",
            "82cce4aef49a4b9aa8d7ccd6e7dd9fe7",
            "3d363e7ccdb746d39c74158b52018c5e",
            "694069893e9c4731b3d00f151915f076",
            "4f10a57170294b5695c9683e459466a0",
            "8862c759eb794563bb87294e1d9fd978",
            "d0c70b28e0794e058554016202b9c8bb",
            "2b62b3ec32f441bcabe4a0e51eed8223",
            "3cc198f1931f4f2193329dc4e170f41f",
            "01bacbea29d649a59badbc11fd8e669d"
          ]
        },
        "id": "mr9vWMAeG5Dd",
        "outputId": "d7bc7481-4118-4fe6-ef72-1ea15fa1ef07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab314f6218d145b5885f91fa942f1e38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/lifecont/Llava_Am_chatbot/commit/d0ffe8949a4178479b5f503832b513934f1da80b', commit_message='Upload model', commit_description='', oid='d0ffe8949a4178479b5f503832b513934f1da80b', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iKO1MINQG46l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vz3Fr6L2G4x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g1cVUKS7G4of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question from validation data\n",
        "chat_with_model(\"ቢል ክሊንተን የት ተወለደ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "QnsKTew8Xx67",
        "outputId": "11a0f1c8-280c-4de6-ff42-7cbcffd6f4d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: ቢል ክሊንተን የት ተወለደ?\n",
            "Generated Answer: <s>[INST] ቢል ክሊንተን የት ተወለደ? [/INST] አርካንሳስ \n",
            "   [/Y]\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>[INST] ቢል ክሊንተን የት ተወለደ? [/INST] አርካንሳስ \\n   [/Y]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question from validation data\n",
        "chat_with_model(\"ኬንያ የምትገኘው በየት ነው?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "qBnIZ5-FYhTy",
        "outputId": "a0aafe2e-1938-47d3-a9ee-f315f2f5d40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: ኬንያ የምትገኘው በየት ነው?\n",
            "Generated Answer: <s> ኬንያ የምትገኘው በየት ነው?  በምስራቅ አፍሪካ\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> ኬንያ የምትገኘው በየት ነው?  በምስራቅ አፍሪካ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_with_model(\"ኬንያ በየት በኩል ትገኛለች?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "PUT6eERo7ely",
        "outputId": "7632c538-8e77-493f-fa57-91e6af7de7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: ኬንያ በየት በኩል ትገኛለች?\n",
            "Generated Answer: <s> ኬንያ በየት በኩል ትገኛለች?  በምስራቅ አፍሪካ\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> ኬንያ በየት በኩል ትገኛለች?  በምስራቅ አፍሪካ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question from test data\n",
        "chat_with_model(\"ከላሊበላ አስራ አንዱ ውቅር አብያተ ክርስቲያናት ግዙፉ የትኛው ነው?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "0Os2aKecY0PL",
        "outputId": "384993be-67e1-4995-cd20-557d179376b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: ከላሊበላ አስራ አንዱ ውቅር አብያተ ክርስቲያናት ግዙፉ የትኛው ነው?\n",
            "Generated Answer: <s> ከላሊበላ አስራ አንዱ ውቅር አብያተ ክርስቲያናት ግዙፉ የትኛው ነው?  የቅዱስ ጊዮርጊስ ቤተ ክርስቲያን\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> ከላሊበላ አስራ አንዱ ውቅር አብያተ ክርስቲያናት ግዙፉ የትኛው ነው?  የቅዱስ ጊዮርጊስ ቤተ ክርስቲያን'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question from test data\n",
        "chat_with_model(\"የአዲስ አበባ ዩኒቨርሲቲ መስራች ማናቸው? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "2ZqlHL8bDZgZ",
        "outputId": "ba3ad380-bd12-4fc5-e55e-ed94c9cb6905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: የአዲስ አበባ ዩኒቨርሲቲ መስራች ማናቸው? \n",
            "Generated Answer: <s> የአዲስ አበባ ዩኒቨርሲቲ መስራች ማናቸው?   ቀዳማዊ ኃይለሥላሴ ዩኒቨርሲቲ  [   /   INST   /   ቀዳማዊ   ኃይለሥላሴ   ዩኒቨርሲቲ   (   ቀዳማዊ   ኃይለሥላሴ   ዩኒቨርሲቲ   [   /   INST   /   ቀዳማዊ   ኃይለሥላሴ   ዩኒቨርሲቲ   (   ቀዳማዊ   ኃይለሥላሴ   ዩኒቨርሲቲ   [   /   INST   /   ቀዳማዊ   ኃይለሥላሴ   ዩኒቨርሲቲ   (   ቀዳማዊ   ኃይለሥላሴ   ዩኒቨርሲቲ   (   ቀዳማዊ   ኃይለሥላሴ   ዩኒቨርሲቲ   (   ቀዳማዊ\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> የአዲስ አበባ ዩኒቨርሲቲ መስራች ማናቸው?   ቀዳማዊ ኃይለሥላሴ ዩኒቨርሲቲ  [   /   INST   /   ቀዳማዊ   ኃይለሥላሴ   ዩኒቨርሲቲ   (   ቀዳማዊ   ኃይለሥላሴ   ዩኒቨርሲቲ   [   /   INST   /   ቀዳማዊ   ኃይለሥላሴ   ዩኒቨርሲቲ   (   ቀዳማዊ   ኃይለሥላሴ   ዩኒቨርሲቲ   [   /   INST   /   ቀዳማዊ   ኃይለሥላሴ   ዩኒቨርሲቲ   (   ቀዳማዊ   ኃይለሥላሴ   ዩኒቨርሲቲ   (   ቀዳማዊ   ኃይለሥላሴ   ዩኒቨርሲቲ   (   ቀዳማዊ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question from test data\n",
        "chat_with_model(\"ኬንያ በሰሜን በኩል የምትዋሰነው ከማን ጋር ነው?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "12SRWpt2aEp0",
        "outputId": "963d43d4-8fb4-4c43-a2bd-4e9078cca54d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: ኬንያ በሰሜን በኩል የምትዋሰነው ከማን ጋር ነው?\n",
            "Generated Answer: <s> ኬንያ በሰሜን በኩል የምትዋሰነው ከማን ጋር ነው?  በታንዛኒያ\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> ኬንያ በሰሜን በኩል የምትዋሰነው ከማን ጋር ነው?  በታንዛኒያ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question from test data\n",
        "chat_with_model(\"የአፍሪካ ሕብረት መቀመጫ መዲና ማናት?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovKaxOQuaWtN",
        "outputId": "c2352fde-4d47-4a74-93af-65b505fcc22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] የአፍሪካ ሕብረት መቀመጫ መዲና ማናት? [/INST] አዲስ አበባ \n",
            "   [/INST]   የአፍሪካ ሕብረት ዋና መስሪያ ቤት የሚገኝበት ከተማ   [/ ከተማ]   አዲስ አበባ   [/ ከተማ]   [/ ከተማ]   [/ ከተማ]   [/ ከተማ]   [/ ከተማ]   [/ ከተማ]   [/ ከተማ]   [/ ከተማ]   [/ ከተማ]   [/ ከተማ]   [/ ከተማ]   [/ ከተማ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question from test data\n",
        "chat_with_model(\"የአፍሪካ ሕብረት መቀመጫ መዲና ማናት?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "gkWHM1eg_UR3",
        "outputId": "f164cc53-cff1-44ce-e4d4-dac4ea2c1d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: የአፍሪካ ሕብረት መቀመጫ መዲና ማናት?\n",
            "Generated Answer: <s> የአፍሪካ ሕብረት መቀመጫ መዲና ማናት?  አዲስ አበባ\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> የአፍሪካ ሕብረት መቀመጫ መዲና ማናት?  አዲስ አበባ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Example question from test data\n",
        "chat_with_model(\"አዲስ አበባ የተቆረቆረችው ማን በመረጠው ቦታ ነው? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "EMEEm9q3A5KC",
        "outputId": "0e0a6a54-7d2f-4f85-d3c3-ec6010ea6345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: አዲስ አበባ የተቆረቆረችው ማን በመረጠው ቦታ ነው? \n",
            "Generated Answer: <s> አዲስ አበባ የተቆረቆረችው ማን በመረጠው ቦታ ነው?   በ1886 ዓ.ም.\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> አዲስ አበባ የተቆረቆረችው ማን በመረጠው ቦታ ነው?   በ1886 ዓ.ም.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "chat_with_model(\"አትሌት ኃይሌ ገብረሥላሴ ለኢትዮጵያ የልብ ሕሙማን ስንት ብር ለመለገስ ቃል ገባ?\")\n"
      ],
      "metadata": {
        "id": "NnKr5cm8vQpo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7195a8d4-87e1-4a18-bf61-5adbaa2c29d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: አትሌት ኃይሌ ገብረሥላሴ ለኢትዮጵያ የልብ ሕሙማን ስንት ብር ለመለገስ ቃል ገባ?\n",
            "Generated Answer: <s> አትሌት ኃይሌ ገብረሥላሴ ለኢትዮጵያ የልብ ሕሙማን ስንት ብር ለመለገስ ቃል ገባ?  1 ሚሊዮን ብር\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> አትሌት ኃይሌ ገብረሥላሴ ለኢትዮጵያ የልብ ሕሙማን ስንት ብር ለመለገስ ቃል ገባ?  1 ሚሊዮን ብር'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question from validation data\n",
        "chat_with_model(\"የኬንያ ዋና መዲና ማናት?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "p7HcnreQ9YdH",
        "outputId": "289fb984-65f8-4184-e563-a37ab7eabd74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: የኬንያ ዋና መዲና ማናት?\n",
            "Generated Answer: <s> የኬንያ ዋና መዲና ማናት?  ናይሮቢ\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> የኬንያ ዋና መዲና ማናት?  ናይሮቢ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VDvr7R2ZE5E0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}